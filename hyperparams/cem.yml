# Tuned
CartPole-v1:
  n_envs: 1
  n_timesteps: !!float 1e5
  policy: 'LinearPolicy'
  pop_size: 4
  n_top: 2

Pendulum-v1: &pendulum-params
  n_envs: 1
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  normalize: "dict(norm_obs=True, norm_reward=False)"
  pop_size: 8
  n_top: 2
  policy_kwargs: "dict(net_arch=[16])"

# TO BE Tuned
LunarLander-v2:
  <<: *pendulum-params
  pop_size: 12
  n_top: 1
  n_timesteps: !!float 2e6

LunarLanderContinuous-v2:
  <<: *pendulum-params
  n_timesteps: !!float 2e6

Acrobot-v1:
  <<: *pendulum-params
  n_timesteps: !!float 5e5

# Tuned
MountainCar-v0:
  <<: *pendulum-params
  pop_size: 16
  n_timesteps: !!float 5e5

# Tuned
MountainCarContinuous-v0:
  <<: *pendulum-params
  n_timesteps: !!float 5e5

# === Pybullet Envs ===

HalfCheetahBulletEnv-v0: &pybullet-defaults
  n_envs: 1
  policy: 'MlpPolicy'
  n_timesteps: !!float 7.5e7
  learning_rate: !!float 0.02
  delta_std: !!float 0.03
  pop_size: 16
  n_top: 8
  alive_bonus_offset: 0
  normalize: "dict(norm_obs=True, norm_reward=False)"
  policy_kwargs: "dict(net_arch=[64])"
  zero_policy: False

# To be tuned
AntBulletEnv-v0:
  n_envs: 1
  policy: 'MlpPolicy'
  n_timesteps: !!float 7.5e7
  learning_rate: !!float 0.02
  delta_std: !!float 0.03
  n_delta: 32
  n_top: 32
  alive_bonus_offset: 0
  normalize: "dict(norm_obs=True, norm_reward=False)"
  policy_kwargs: "dict(net_arch=[128, 64])"
  zero_policy: False


Walker2DBulletEnv-v0:
  policy: 'MlpPolicy'
  n_timesteps: !!float 7.5e7
  learning_rate: !!float 0.03
  delta_std: !!float 0.025
  n_delta: 40
  n_top: 30
  alive_bonus_offset: -1
  normalize: "dict(norm_obs=True, norm_reward=False)"
  policy_kwargs: "dict(net_arch=[64, 64])"
  zero_policy: False

HopperBulletEnv-v0:
  n_envs: 1
  policy: 'LinearPolicy'
  n_timesteps: !!float 7e6
  learning_rate: !!float 0.01
  delta_std: !!float 0.025
  n_delta: 8
  n_top: 4
  alive_bonus_offset: -1
  normalize: "dict(norm_obs=True, norm_reward=False)"

ReacherBulletEnv-v0:
  <<: *pybullet-defaults
  n_timesteps: !!float 1e6

# === Mujoco Envs ===
# Tuned
Swimmer-v3:
  <<: *pendulum-params
  n_timesteps: !!float 1e6

Hopper-v3:
  <<: *pendulum-params
  n_timesteps: !!float 1e6
  pop_size: 16
  n_top: 4
  alive_bonus_offset: -1

HalfCheetah-v3:
  <<: *pendulum-params
  n_timesteps: !!float 1e6
  pop_size: 16
  n_top: 4
  alive_bonus_offset: 0

Walker2d-v3:
  n_envs: 1
  policy: 'LinearPolicy'
  n_timesteps: !!float 7.5e7
  pop_size: 40
  n_top: 30
  alive_bonus_offset: -1
  normalize: "dict(norm_obs=True, norm_reward=False)"

Ant-v3:
  n_envs: 1
  policy: 'LinearPolicy'
  n_timesteps: !!float 7.5e7
  pop_size: 60
  n_top: 20
  alive_bonus_offset: -1
  normalize: "dict(norm_obs=True, norm_reward=False)"


Humanoid-v3:
  n_envs: 1
  policy: 'LinearPolicy'
  n_timesteps: !!float 2.5e8
  pop_size: 256
  n_top: 256
  alive_bonus_offset: -5
  normalize: "dict(norm_obs=True, norm_reward=False)"

BipedalWalker-v3:
  n_envs: 1
  policy: 'MlpPolicy'
  n_timesteps: !!float 1e8
  pop_size: 64
  n_top: 32
  alive_bonus_offset: -0.1
  normalize: "dict(norm_obs=True, norm_reward=False)"
  policy_kwargs: "dict(net_arch=[16])"

# TO Be Tuned
BipedalWalkerHardcore-v3:
  n_envs: 1
  policy: 'MlpPolicy'
  n_timesteps: !!float 5e8
  pop_size: 64
  n_top: 32
  alive_bonus_offset: -0.1
  normalize: "dict(norm_obs=True, norm_reward=False)"
  policy_kwargs: "dict(net_arch=[16])"

A1Walking-v0:
  <<: *pendulum-params
  n_timesteps: !!float 2e6

A1Jumping-v0:
  policy: 'LinearPolicy'
  n_timesteps: !!float 7.5e7
  pop_size: 80
  n_top: 30
  # alive_bonus_offset: -1
  normalize: "dict(norm_obs=True, norm_reward=False)"
  # policy_kwargs: "dict(net_arch=[16])"
